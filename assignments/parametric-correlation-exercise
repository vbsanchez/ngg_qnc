>> WingLength = [10.4 10.8 11.1 10.2 10.3 10.2 10.7 10.5 10.8 11.2 10.6 11.4];
TailLength = [7.4 7.6 7.9 7.2 7.4 7.1 7.4 7.2 7.8 7.7 7.8 8.3];
>> mwing = mean(WingLength)

mwing =

   10.6833

>> mtail = mean(TailLength)

mtail =

    7.5667

>> figure
plot(TailLength, WingLength, 'ko');
xlabel('Tail Length (cm)');
ylabel('Wing Length (cm)');
>> % yes, they look related
>> % 2. yes, they are the same answers 
>> n           = length(WingLength); %alternatively, you can calculate n=length(TailLength)
sampleMeanX = sum(WingLength)./n;
sampleMeanY = sum(TailLength)./n;
SSEX        = sum((WingLength - sampleMeanX).^2);
SSEY        = sum((TailLength - sampleMeanY).^2);
SCOVXY      = sum((WingLength - sampleMeanX).*(TailLength - sampleMeanY));
rXY         = SCOVXY/(sqrt(SSEX)*sqrt(SSEY));
rYX         = SCOVXY/(sqrt(SSEY)*sqrt(SSEX));
>> % Use corrcoef
rBuiltIn    = corrcoef(WingLength, TailLength);

% Show that they are all the same
disp(sprintf('rXY=%.4f (computed), %.4f (built-in)', rXY, rBuiltIn(1,2)))
disp(sprintf('rYX=%.4f (computed), %.4f (built-in)', rYX, rBuiltIn(2,1)))
rXY=0.8704 (computed), 0.8704 (built-in)
rYX=0.8704 (computed), 0.8704 (built-in)
>> sr   = sqrt((1-rXY^2)/(n-2));
z    = 0.5.*log((1+rXY)/(1-rXY));
sz   = sqrt(1/(n-3));
zs   = z+[1 -1].*norminv(0.025).*sz;
CI95 = (exp(2.*zs)-1)./(exp(2.*zs)+1);
disp(sprintf('sem=%.4f, 95 pct CI = [%.4f %.4f]', sr, CI95(1), CI95(2)))
sem=0.1557, 95 pct CI = [0.5923 0.9632]
>> %3. Standard error: 0.1557 | Confidence Intervals: [0.5923 0.9632]
>> Tval = rXY/sr;           % Compute t statistic
prob = 1-tcdf(Tval,n-2); % Compute p, using n-2 degrees of freedom
disp(sprintf('p=%.4f for H0: r=0', prob))
p=0.0001 for H0: r=0
>> %4. Yes, it should be considered significant
>> zme   = 0.5*log((1+rXY)/(1-rXY));
zyale = 0.5*log((1+0.75)/(1-0.75));
Z     = (zme-zyale)/sqrt(1/(n-3));
prob2 = 1-tcdf(Z/2,inf);
disp(sprintf('p=%.4f for H0: r=0.75', prob2))
p=0.2938 for H0: r=0.75
>> v=n-2;
zm=0.5*log((1+rXY)/(1-rXY));

tcrit=tinv(1-0.05/2,n-2);
rcrit=sqrt(tcrit^2/(tcrit^2+(n-2)));
zr=0.5*log((1+rcrit)/(1-rcrit));

Zb=(zm-zr)*sqrt(n-3);
power=normcdf(Zb);
disp(['The power of the test of H0:r=0 is ' num2str(power)])

%calculate the n needed to ensure that H0 (r=0) is rejected 99% of the time
%when |r|>= 0.5 at a 0.05 level of significance
Often = 0.01; %we want to reject H0 (1-often)% of the time [here, 99%]
rho=0.5; % when r >=0.5
AlphaValue=0.05; % and the hypothesis is tested at AlphaValue of significance
Zb=tinv(1-Often,inf);
Za=tinv(1-AlphaValue/2,inf);
zeta=0.5*log((1+rho)/(1-rho));
SampleSize=round(((Zb+Za)/zeta)^2+3);
disp(['To reject H0:r=0 99% of the time, when r=0.5 and alpha=0.05, we need n>=' num2str(SampleSize)])
The power of the test of H0:r=0 is 0.97904
To reject H0:r=0 99% of the time, when r=0.5 and alpha=0.05, we need n>=64
>> %5. No, p value is not significant. They are different. 
>> % 6. In order to get an r > 0.5, we need 64 samples. 
